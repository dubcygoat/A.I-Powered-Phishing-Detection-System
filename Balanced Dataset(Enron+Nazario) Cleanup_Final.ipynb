{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a62eba4",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101e2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import os, sys, email,re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47199a3c",
   "metadata": {},
   "source": [
    "# DATASET  LOADING \n",
    "\"\"\"The code above imports the pandas library and reads two CSV files into dataframes. \n",
    "The read_csv function from pandas is used to read the CSV files. In the case of 'emails.csv', \n",
    "the number of rows is limited to 3900 using the nrows parameter. In the case of 'nazario_recent.csv', \n",
    "the index column is set to the first column using the index_col parameter, and the data type of the 'body' column \n",
    "is set to a generic object using the dtype parameter.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e762ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read 'emails.csv' file into a dataframe with a limit of 3900 rows(Benign Corpus)\n",
    "df = pd.read_csv('emails.csv', nrows=3900)\n",
    "\n",
    "# Read 'nazario_recent.csv' file into a dataframe with the first column as the index column\n",
    "# Set the data type of the 'body' column as a generic object(Phishing Corpus)\n",
    "jf = pd.read_csv('nazario_recent.csv', index_col=0, dtype={'body': 'object'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af4ace",
   "metadata": {},
   "source": [
    "# EMAIL PARSING FOR BENIGN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c12b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract information such as the subject, sender, and recipient of each email\n",
    "  then create new columns in the DataFrame for each piece of extracted information.\"\"\" #Code reference(https://www.kaggle.com/code/jxm222/clustering-mail/notebook)\n",
    "\n",
    "\n",
    "# Parse each email message in the \"message\" column of the DataFrame\n",
    "emails = list(map(email.parser.Parser().parsestr, df['message']))\n",
    "\n",
    "# extract headings from the first email object in the list of emails such as subject, from, to etc..\n",
    "headings = emails[0].keys()\n",
    "\n",
    "\"\"\"Loop through each heading, extract the corresponding values from each email object in the list, \n",
    "and create a new column in the DataFrame with the heading as the column name and the extracted \n",
    "values as the column values\"\"\" \n",
    "for key in headings:\n",
    "    df[key] = [doc[key] for doc in emails]\n",
    "\n",
    "    \n",
    "# Define a function to extract the raw text from each email object in the list of emails\n",
    "def get_raw_text(emails):\n",
    "    email_text = []\n",
    "    for email in emails.walk():\n",
    "        if email.get_content_type() == 'text/plain':\n",
    "            email_text.append(email.get_payload())\n",
    "    return ''.join(email_text)\n",
    "\n",
    "\"\"\"Apply the \"get_raw_text\" function to each email object in the list of emails,and store \n",
    "the resulting strings in a new column called \"message\" in the DataFrame\n",
    "\"\"\"\n",
    "df['message'] = list(map(get_raw_text, emails))\n",
    "\n",
    "\"\"\"Extract the username from the file path of each email,and store the usernames in a new column called\n",
    "\"user\" in the DataFrame\"\"\"\n",
    "\n",
    "df['user'] = df['file'].map(lambda x: x.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b836ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file                                                    allen-p/_sent_mail/10.\n",
      "message                      Traveling to have a business meeting takes the...\n",
      "Message-ID                       <15464986.1075855378456.JavaMail.evans@thyme>\n",
      "Date                                      Fri, 4 May 2001 13:51:00 -0700 (PDT)\n",
      "From                                                   phillip.allen@enron.com\n",
      "To                                                     john.lavorato@enron.com\n",
      "Subject                                                                    Re:\n",
      "Mime-Version                                                               1.0\n",
      "Content-Type                                      text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding                                                 7bit\n",
      "X-From                                                         Phillip K Allen\n",
      "X-To                         John J Lavorato <John J Lavorato/ENRON@enronXg...\n",
      "X-cc                                                                          \n",
      "X-bcc                                                                         \n",
      "X-Folder                     \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...\n",
      "X-Origin                                                               Allen-P\n",
      "X-FileName                                         pallen (Non-Privileged).pst\n",
      "user                                                                   allen-p\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7eaad68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file', 'message', 'Message-ID', 'Date', 'From', 'To', 'Subject',\n",
       "       'Mime-Version', 'Content-Type', 'Content-Transfer-Encoding', 'X-From',\n",
       "       'X-To', 'X-cc', 'X-bcc', 'X-Folder', 'X-Origin', 'X-FileName', 'user'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the new columns after parsing the email method on the Benign Dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a5118ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\n",
      "\n",
      "As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \n",
      "\n",
      "My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read the first index of the message column of the benign dataset\n",
    "print(df['message'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910fbad3",
   "metadata": {},
   "source": [
    "# PHISHING CLEANUP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8381fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1918 entries, 0 to 2162\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    1917 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 30.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Get information about the Phishing Dataset before cleaning\n",
    "jf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2dfab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary preprocessing libraries for the cleaning(Reference:https://github.com/liakoyras/thesis-phishing-email-detection)\n",
    "\n",
    "from raw_utils import save_to_csv\n",
    "import preprocessing as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6a3ba12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Duplicate rows\n",
    "jf = jf[jf.duplicated(keep='first') == False]\n",
    "\n",
    "#View the new shape\n",
    "jf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423385bf",
   "metadata": {},
   "source": [
    "# LEGITIMATE(BENIGN) EMAILS CLEANUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9eb9f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dropping Columns not needed in our ML model building\n",
    "\n",
    "df = df.drop(['file', 'Message-ID', 'Date', 'From', 'To', 'Subject',\n",
    "       'Mime-Version', 'Content-Type', 'Content-Transfer-Encoding', 'X-From',\n",
    "       'X-To', 'X-cc', 'X-bcc', 'X-Folder', 'X-Origin', 'X-FileName', 'user'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d312677f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get new information of the Benign Corpus\n",
    "df.info\n",
    "\n",
    "#View the new shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "10faacf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   body\n",
      "0                             Here is our forecast\\n\\n \n",
      "1     Traveling to have a business meeting takes the...\n",
      "2                        test successful.  way to go!!!\n",
      "3     Randy,\\n\\n Can you send me a schedule of the s...\n",
      "4                   Let's shoot for Tuesday at 11:45.  \n",
      "...                                                 ...\n",
      "3895  asshole\\n\\n\\n\\n\\nJohn J Lavorato@ENRON\\n12/24/...\n",
      "3896  the market had to get to a price whereby these...\n",
      "3897  ---------------------- Forwarded by Sarah-Joy ...\n",
      "3898  ---------------------- Forwarded by John Arnol...\n",
      "3899  i know\\n\\n\\n\\n\\nJennifer Shipos\\n12/21/2000 12...\n",
      "\n",
      "[3900 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Drop Null Rows and Rename the column\n",
    "\n",
    "\n",
    "#Rename the column message to body\n",
    "df = df.rename(columns={'message':'body'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26898117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null Rows\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dde0122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the new shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5852e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for empty emails\n",
    "df = df[df['body'].apply(util.check_empty) == False]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a775a114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2210, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for Duplicates\n",
    "df = df[df.duplicated(keep='first') == False]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e41a1dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body'], dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the Column of the new Dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e37e8",
   "metadata": {},
   "source": [
    "# Creating a Mixed Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5211a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This Step creates a combined dataset of the two dataframes and add an extra column named \"class\" \n",
    "to classify the emails as either phishing or legitimate.The Balanced dataset will be 1:1\"\"\"\n",
    "\n",
    "\n",
    "#Create the column for the phishing dataset with value 1 to represent phishing\n",
    "jf['class'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31fc47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample a random set of 1918 rows from the benign dataframe to match the number of rows \n",
    "#in the phishing dataframe and set create an extra column and set the class to 0 to indicate legitimate emails\n",
    "\n",
    "df = df.sample(n=1918, random_state = 1746)\n",
    "df['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee64ae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThis is for the Legitimate emails:\n",
      "\u001b[0;0m                                                    body  class\n",
      "1196  Scott,\\n\\n Thanks for the email.  I have two q...      0\n",
      "1412  [IMAGE]\\nNCI Marketing Web Alert \\t\\n\\n\\n[IMAG...      0\n",
      "1295  phillip.\\n\\nlooking into it now, i'll move the...      0\n",
      "2274  \\n\\n -----Original Message-----\\nFrom: \\t\"JEFF...      0\n",
      "442   I would like to have a copy of the appraisal. ...      0\n",
      "...                                                 ...    ...\n",
      "3848  Jennifer,\\nI just checked with Carolyn on your...      0\n",
      "1232  \\n \\n>From: \"Greg Thorse\" \\n>To: \\n>CC: \"Phill...      0\n",
      "3521  planning on going.  which night are you inviti...      0\n",
      "1475  The following expense report is ready for appr...      0\n",
      "2206  Tim,\\n\\nIs something wrong with the database? ...      0\n",
      "\n",
      "[1918 rows x 2 columns]\n",
      "\u001b[1mThis is for the Phishing emails:\n",
      "\u001b[0;0m                                                    body  class\n",
      "0       Microsoft Failure Delivery Notice.\\n  User: ...      1\n",
      "2       Microsoft Failure Delivery Notice.\\n  User: ...      1\n",
      "3     Microsoft Failure Delivery Notice.\\n  User: jo...      1\n",
      "4     Microsoft Failure Delivery Notice.\\n  User: jo...      1\n",
      "5       \\n   \\t   \\n   New Voice Message\\n  New Call...      1\n",
      "...                                                 ...    ...\n",
      "2158  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\tbody {\\n\\t\\t\\t...      1\n",
      "2159  Microsoft Failure Delivery Notice.\\n  User: jo...      1\n",
      "2160  Dear jose,\\nYour email quota is low and cannot...      1\n",
      "2161  Dear jose\\nTo continue using your address jose...      1\n",
      "2162  \\n\\n\\n    SpotifyÂ®\\n\\t\\n \\n\\nWe are facing dif...      1\n",
      "\n",
      "[1918 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#View the dataframes\n",
    "\n",
    "print(\"\\033[1m\" + \"This is for the Legitimate emails:\\n\" + \"\\033[0;0m\",df)\n",
    "print(\"\\033[1m\" + \"This is for the Phishing emails:\\n\" + \"\\033[0;0m\",jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f9c0a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create the Mixed dataframe and insert a new column id at the left-most column \n",
    "to help create an easy reference on individual rows incase we need to perform operations on them.\"\"\"\n",
    "\n",
    "balanced = pd.concat ([jf, df])\n",
    "\n",
    "#Shuffle rows in a random order from the initial combined order\n",
    "balanced = balanced.sample(frac=1, random_state=1746).reset_index(drop=True)\n",
    "\n",
    "#Create the new column id from the first index\n",
    "balanced.insert(0, 'id', balanced.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad3f6a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3836, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the new comibined dataframe\n",
    "balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7235f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a csv file path and save the balanced dataset for further processing\n",
    "csv_path = os.path.join('/Users/mimidubcys/Desktop/Projects/A.I Powered Phishing Detection System/Project Files/Phishing Datasets/Phishing Detection Coding Task')\n",
    "\n",
    "save_to_csv(balanced,csv_path,'balanced.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

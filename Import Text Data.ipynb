{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d06d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference: https://github.com/liakoyras/thesis-phishing-email-detection\n",
    "import raw_utils as util\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "random.seed(1746)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d44b790",
   "metadata": {},
   "source": [
    "## Phishing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca6e53",
   "metadata": {},
   "source": [
    "### Nazario Phishing Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68fd7e9",
   "metadata": {},
   "source": [
    "We will start with reading the subset of the Phishing Corpus that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953aa18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "cwd = os.getcwd()\n",
    "nazario_path = os.path.join(cwd, 'monkey.org/~jose/phishing')\n",
    "enron_path = os.path.join(cwd, 'data/legitimate/enron/')\n",
    "\n",
    "csv_path = os.path.join(cwd, 'data/csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b479cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to be ignored for read_dataset()\n",
    "files_ignored = ['README.txt']\n",
    "files_ignored_recent = ['README.txt', '20051114.mbox',  'phishing0.mbox',  'phishing1.mbox',  'phishing2.mbox',  'phishing3.mbox', 'private-phishing4.mbox']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c39ca9",
   "metadata": {},
   "source": [
    "First, we will read and convert all of the dataset. It is straightforward since it is a collection of .mbox files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21c5331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading file: phishing-2022\n",
      "Now reading file: 20051114.mbox\n",
      "Now reading file: phishing-2015\n",
      "Now reading file: phishing2.mbox\n",
      "Now reading file: phishing3.mbox\n",
      "Now reading file: phishing-2021\n",
      "Now reading file: phishing-2019\n",
      "Now reading file: phishing-2017\n",
      "Now reading file: phishing0.mbox\n",
      "Now reading file: phishing-2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mimidubcys/opt/anaconda3/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading file: phishing-2018\n",
      "Now reading file: phishing-2020\n",
      "Now reading file: phishing1.mbox\n",
      "Now reading file: private-phishing4.mbox\n",
      "1 emails skipped: Headers contain non-ascii characters, or otherwise corrupted email data.\n"
     ]
    }
   ],
   "source": [
    "phishing = util.read_dataset(nazario_path, files_ignored, text_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4586c7c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10706 entries, 0 to 10705\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    10706 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 83.8+ KB\n"
     ]
    }
   ],
   "source": [
    "phishing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fc41143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to /Users/mimidubcys/Downloads/thesis-phishing-email-detection-main/data/csv/nazario_full.csv\n"
     ]
    }
   ],
   "source": [
    "util.save_to_csv(phishing, csv_path, 'nazario_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861526a",
   "metadata": {},
   "source": [
    "Then, we will also take the subset of only the recent emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "630849ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading file: phishing-2022\n",
      "Now reading file: phishing-2015\n",
      "Now reading file: phishing-2021\n",
      "Now reading file: phishing-2019\n",
      "Now reading file: phishing-2017\n",
      "Now reading file: phishing-2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mimidubcys/opt/anaconda3/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading file: phishing-2018\n",
      "Now reading file: phishing-2020\n"
     ]
    }
   ],
   "source": [
    "phishing_recent = util.read_dataset(nazario_path, files_ignored_recent, text_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a1c26f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2163 entries, 0 to 2162\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    2163 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 17.0+ KB\n"
     ]
    }
   ],
   "source": [
    "phishing_recent.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82f2ecea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to /Users/mimidubcys/Downloads/thesis-phishing-email-detection-main/data/csv/nazario_recent.csv\n"
     ]
    }
   ],
   "source": [
    "util.save_to_csv(phishing_recent, csv_path, 'nazario_recent.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
